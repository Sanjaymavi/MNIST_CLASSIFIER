{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2225e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "#mnist = modified national institute of standards and technology database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38d2e327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOWNLOADING TRAINING DATA\n",
    "\n",
    "dataset = MNIST(root='data/' , download=True)\n",
    "#MNIST=MODIFIED NATIONAL INSTITUTE OF STANDARDS AND TECHNOLOGY DATASETS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4093469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset) # we have 60k datasets here for training the model . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85ca26a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = MNIST(root='data/' , train=False)  # here we have 10k datasets for testing the model.\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7700548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = MNIST(root='data/' , train=True)  # training datasets 60k\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "222aad7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x10DA94BF580>, 5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]  # 28x28 image , 5 label image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fcf6bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "# these command helps to see the images in our jupyter not as a popup.\n",
    "#for more commands like these visit.  https://ipython.reasthedocs.io/en/stable/interactive/magics.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a19bf297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = dataset[0]\n",
    "plt.imshow(image, cmap= 'gray')  #colourmap=cmap\n",
    "print('label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44e434ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = dataset[10]\n",
    "plt.imshow(image, cmap= 'gray')  #colourmap=cmap\n",
    "print('label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "548a5534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok WE GOT IMAGES BUT PYTORCH DOES'NT KNOW HOW TO WORK WITH IMAGES , IT WORKS ONLY WITH TENSORS.SO WE NEED TO CONVERT IT INTO TENSORS\n",
    "\n",
    "import torchvision .transforms as transforms\n",
    "\n",
    "# here we use \"ToTensor\" transform to convert the images to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5555d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST DATASET (images , labels)\n",
    "dataset = MNIST(root='data/' , train=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3053dd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 5\n"
     ]
    }
   ],
   "source": [
    "img_tensor, label = dataset[0]\n",
    "print(img_tensor.shape, label)\n",
    "# here the is converted to tensor of (1x28x28) tensor.the first dimension is used to keep track of colour channels.but in grayscale \n",
    "# so they're just one channel. other datasets have images with three colour channels ,red,green,blue(RGB).\n",
    "#AND other (28x28)  gives height and width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be01fec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0039, 0.6039, 0.9922, 0.3529, 0.0000],\n",
      "         [0.0000, 0.5451, 0.9922, 0.7451, 0.0078],\n",
      "         [0.0000, 0.0431, 0.7451, 0.9922, 0.2745],\n",
      "         [0.0000, 0.0000, 0.1373, 0.9451, 0.8824],\n",
      "         [0.0000, 0.0000, 0.0000, 0.3176, 0.9412]]])\n",
      "tensor(1.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(img_tensor[:,10:15,10:15])\n",
    "print(torch.max(img_tensor), torch.min(img_tensor))  #max=torch(1.)=white region , min=torch(0.)=black region in image\n",
    "# here we calculate the intensity of dataset[0] from 20 to 25 in both x and y axis\n",
    "# in output there is zeroes(minimum) rpresents dark black , and values in decimals represents white.higher value more white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b0e58d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118,\n",
      "          0.0706, 0.0706],\n",
      "         [0.0000, 0.0000, 0.0000, 0.1176, 0.1412, 0.3686, 0.6039, 0.6667,\n",
      "          0.9922, 0.9922],\n",
      "         [0.0000, 0.0000, 0.1922, 0.9333, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922],\n",
      "         [0.0000, 0.0000, 0.0706, 0.8588, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.7765],\n",
      "         [0.0000, 0.0000, 0.0000, 0.3137, 0.6118, 0.4196, 0.9922, 0.9922,\n",
      "          0.8039, 0.0431],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.0039, 0.6039, 0.9922,\n",
      "          0.3529, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5451, 0.9922,\n",
      "          0.7451, 0.0078],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.7451,\n",
      "          0.9922, 0.2745],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1373,\n",
      "          0.9451, 0.8824],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.3176, 0.9412]]])\n",
      "tensor(1.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(img_tensor[:,5:15,5:15])\n",
    "print(torch.max(img_tensor), torch.min(img_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d48645d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_tensor[0,10:15,10:15],cmap='gray');\n",
    "#here \"IMSHOW\" helps to plot the region , "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2cc9e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING AND VALIDATION DATASETS;\n",
    "#while building the model we split the data into three sets \n",
    "#1.) training set: train the model, compute loss and adjust the weights of the model using gradient descent.\n",
    "#2.)validation set:used to evaluate the model while training , adjust hyperparameter (learning rate,etc), and picks the best version of model.\n",
    "#3.)test set : used to compare different models , or different types of modeling approaches, and report the final accuracy of the model.\n",
    "\n",
    "#here we have60k training dataset there is no validation set , we only split it accordingly for our use of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff532fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_indices(n, val_pct):   # we know n= 60k\n",
    "    #determine size of validation set\n",
    "    n_val = int(val_pct*n)\n",
    "    #create random permutation of 0 to n-1\n",
    "    idxs = np.random.permutation(n)\n",
    "    #pick first n_val indices for validation\n",
    "    return idxs[n_val:], idxs[:n_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9191483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, val_indices = split_indices(len(dataset), val_pct=0.2)\n",
    "#here we take 20% of total n to val_pct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d1f9bcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 12000\n",
      "sample val indices:  [30082 45645 32425 32104 51003  8743 44044 56723  7816  3686]\n"
     ]
    }
   ],
   "source": [
    "print(len(train_indices), len(val_indices))\n",
    "print('sample val indices: ' , val_indices[:10])\n",
    "#48k for training, 12k for validation.\n",
    "#here we get shuffled val_pct data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b33ced21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING THE PYTORCH DATALOADER FOR EACH OF THESE USING THE \"SUBSETRANDOMSAMPLER\" ,which samples elements randomly from a given list of indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2f9bdcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ea20cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "#we create batches for our training and validation dataset.\n",
    "#training sampler and dataloader\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "train_loader = DataLoader(dataset, batch_size, sampler=train_sampler)\n",
    "\n",
    "#validation sampler and dataloader\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "val_loader = DataLoader(dataset , batch_size , sampler=train_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b21b411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL\n",
    "#logistic is similar to linear regression.where output is sum of all inputs multiplied with weights \n",
    "#pred = x@w.t()+b\n",
    "#here also we use \"nn.linear\" to create a model , and nn.linear expects each training example to be vector, so each(1x28x28) \n",
    "#image  tensor needs to be flattened out into a vector of size 784(28x28) befor passsing into the model.\n",
    "#the output for each image is vector of size 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5dec371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_size = 28*28\n",
    "num_classes = 10\n",
    "\n",
    "#logistic regression model\n",
    "model = nn.Linear(input_size , num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a1053b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0092, -0.0041, -0.0336,  ..., -0.0218,  0.0259, -0.0290],\n",
       "        [ 0.0354, -0.0341, -0.0130,  ..., -0.0036,  0.0302, -0.0060],\n",
       "        [-0.0354,  0.0335, -0.0092,  ...,  0.0139, -0.0238, -0.0085],\n",
       "        ...,\n",
       "        [ 0.0259,  0.0220, -0.0228,  ..., -0.0176, -0.0162, -0.0249],\n",
       "        [-0.0215, -0.0043,  0.0012,  ...,  0.0079,  0.0035,  0.0179],\n",
       "        [ 0.0037,  0.0215,  0.0296,  ...,  0.0226, -0.0286, -0.0176]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CREATING WEIGHTS\n",
    "print(model.weight.shape)\n",
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4603515b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0067, -0.0286,  0.0306,  0.0094, -0.0020, -0.0145, -0.0198, -0.0296,\n",
       "        -0.0065, -0.0156], requires_grad=True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CREATING BIAS\n",
    "print(model.bias.shape)\n",
    "model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2348d71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 6, 3, 7, 9, 2, 0, 3, 9, 7, 3, 9, 0, 0, 8, 0, 6, 1, 1, 9, 0, 5, 8, 0,\n",
      "        1, 6, 8, 8, 7, 8, 0, 3, 5, 1, 8, 7, 3, 7, 3, 4, 6, 4, 7, 0, 9, 4, 0, 6,\n",
      "        8, 4, 0, 6, 8, 4, 0, 7, 7, 1, 6, 7, 6, 9, 2, 3, 4, 0, 6, 0, 8, 3, 8, 5,\n",
      "        3, 5, 7, 9, 0, 8, 7, 7, 9, 5, 2, 7, 4, 2, 2, 8, 3, 0, 5, 8, 1, 8, 3, 5,\n",
      "        7, 9, 2, 3])\n",
      "torch.Size([100, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2800x28 and 784x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7656/1109417557.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#we get error of showing the model images , because the shape is not matching one is (28x28) and another one is (784 )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2800x28 and 784x10)"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(labels)\n",
    "    print(images.shape)\n",
    "    outputs = model(images)\n",
    "    break\n",
    "    #we get error of showing the model images , because the shape is not matching one is (28x28) and another one is (784 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f84fa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the error above is because of the input data doesnt have the right shape , our images are of shape 1x28x28 , but we need 784, \n",
    "#so we need to flatten , for that we use \".reshape\" mthod of a tensor , which helps us to view efficiently view each images as\n",
    "#a flat vector without really changing the underlying data.\n",
    "\n",
    "#we include a custom model by extending the nn.module class from pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ca6f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "model = MnistModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aab462e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=10, bias=True)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "583596cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784]) torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0279, -0.0348, -0.0328,  ...,  0.0217,  0.0054, -0.0280],\n",
       "         [ 0.0258,  0.0054, -0.0341,  ..., -0.0092, -0.0203, -0.0012],\n",
       "         [ 0.0163,  0.0353, -0.0250,  ..., -0.0281, -0.0120, -0.0228],\n",
       "         ...,\n",
       "         [ 0.0213,  0.0228, -0.0096,  ...,  0.0316,  0.0183,  0.0122],\n",
       "         [ 0.0179,  0.0157,  0.0342,  ..., -0.0039, -0.0041, -0.0168],\n",
       "         [ 0.0184,  0.0064, -0.0077,  ..., -0.0142,  0.0132,  0.0061]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0169, -0.0273,  0.0265,  0.0317,  0.0153,  0.0204, -0.0326,  0.0300,\n",
       "          0.0183, -0.0274], requires_grad=True)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.linear.weight.shape, model.linear.bias.shape)\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2ad8bc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1b484292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs.shape:  torch.Size([100, 10])\n",
      "Sample outputs:\n",
      " tensor([[ 1.3579e-01, -6.3904e-02,  2.7110e-02, -1.4010e-01, -2.1289e-01,\n",
      "         -1.0043e-01,  2.0502e-02, -1.2730e-01,  1.0918e-01,  8.8363e-02],\n",
      "        [-9.4032e-02,  2.2026e-02, -5.0344e-02, -1.8742e-01, -3.4288e-01,\n",
      "          1.2376e-01,  1.1110e-01,  4.5179e-02,  2.4784e-02, -4.5173e-02],\n",
      "        [ 1.8942e-01,  1.4572e-02,  2.1869e-01,  1.2516e-01,  1.4549e-01,\n",
      "         -4.6556e-01, -4.6326e-04, -1.1562e-03, -1.3421e-01, -1.1508e-01]])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    outputs = model(images)\n",
    "    break\n",
    "    \n",
    "print('outputs.shape: ', outputs.shape)\n",
    "print('Sample outputs:\\n', outputs[:3].data)\n",
    "#here we get a model images , by converting the 28x28 into vector .\n",
    "#for every image there are ten(10) classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf21a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO CONVERT THE OUTPUT ROWS TO PROBABILITY WE USE SOFTMAX FUNCTION, where we have [eyi/summation eyi] , where y is the value from output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ed9f2a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample probablities:\n",
      " tensor([[0.1169, 0.0957, 0.1048, 0.0887, 0.0825, 0.0923, 0.1041, 0.0898, 0.1138,\n",
      "         0.1114],\n",
      "        [0.0939, 0.1054, 0.0980, 0.0855, 0.0732, 0.1167, 0.1152, 0.1079, 0.1057,\n",
      "         0.0986],\n",
      "        [0.1191, 0.1000, 0.1226, 0.1117, 0.1140, 0.0619, 0.0985, 0.0984, 0.0862,\n",
      "         0.0878],\n",
      "        [0.1055, 0.0897, 0.1000, 0.0852, 0.1366, 0.0778, 0.0978, 0.1180, 0.0939,\n",
      "         0.0956]])\n",
      "sum:  0.9999999403953552\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "#apply softmax for each output row\n",
    "probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "#look at sample probabilities\n",
    "print(\"Sample probablities:\\n\" , probs[:4].data)\n",
    "\n",
    "#add up the probabilitites of an output row\n",
    "print(\"sum: \", torch.sum(probs[0]).item())   # calculating the sum for 0 row \n",
    "#here we calculated probability of all numbers\n",
    "# # and we know in probability sum of all values is equal to one(1), more equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "256e404a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 5, 2, 4, 8, 8, 8, 6, 0, 0, 0, 2, 0, 7, 6, 8, 2, 9, 6, 6, 0, 6, 8, 0,\n",
      "        8, 0, 0, 6, 0, 6, 8, 1, 1, 0, 8, 2, 0, 0, 8, 6, 5, 7, 0, 7, 2, 8, 6, 8,\n",
      "        8, 8, 0, 0, 0, 6, 8, 5, 3, 7, 0, 6, 8, 8, 0, 8, 1, 5, 0, 7, 1, 8, 1, 8,\n",
      "        1, 6, 2, 7, 3, 0, 0, 2, 2, 6, 5, 5, 7, 2, 2, 2, 0, 8, 6, 0, 4, 0, 6, 0,\n",
      "        5, 7, 0, 8])\n",
      "tensor([0.1169, 0.1167, 0.1226, 0.1366, 0.1611, 0.1258, 0.1238, 0.1272, 0.1409,\n",
      "        0.1274, 0.1289, 0.1568, 0.1473, 0.1326, 0.1262, 0.1158, 0.1268, 0.1246,\n",
      "        0.1154, 0.1154, 0.1206, 0.1413, 0.1194, 0.1174, 0.1551, 0.1438, 0.1081,\n",
      "        0.1411, 0.1161, 0.1185, 0.1441, 0.1315, 0.1407, 0.1241, 0.1373, 0.1080,\n",
      "        0.1358, 0.1236, 0.1291, 0.1437, 0.1372, 0.1322, 0.1413, 0.1296, 0.1272,\n",
      "        0.1504, 0.1143, 0.1242, 0.1311, 0.1290, 0.1529, 0.1460, 0.1190, 0.1127,\n",
      "        0.1336, 0.1267, 0.1211, 0.1239, 0.1253, 0.1188, 0.1304, 0.1452, 0.1314,\n",
      "        0.1445, 0.1207, 0.1220, 0.1331, 0.1525, 0.1215, 0.1412, 0.1308, 0.1497,\n",
      "        0.1186, 0.1225, 0.1418, 0.1188, 0.1266, 0.1257, 0.1397, 0.1257, 0.1206,\n",
      "        0.1353, 0.1304, 0.1257, 0.1291, 0.1417, 0.1390, 0.1208, 0.1225, 0.1549,\n",
      "        0.1454, 0.1391, 0.1113, 0.1305, 0.1251, 0.1150, 0.1200, 0.1272, 0.1172,\n",
      "        0.1224], grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "max_probs , preds = torch.max(probs, dim=1)   # here torch.max picks the best probability and best indices among all.\n",
    "print(preds) #gives random labels\n",
    "print(max_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a462cb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 6, 3, 3, 0, 3, 2, 6, 6, 3, 5, 6, 5, 0, 7, 1, 0, 1, 4, 7, 7, 0, 1, 8,\n",
       "        0, 6, 5, 7, 5, 9, 8, 8, 4, 3, 5, 1, 6, 8, 5, 5, 4, 3, 0, 3, 4, 2, 7, 6,\n",
       "        8, 5, 6, 6, 8, 2, 5, 7, 3, 7, 7, 7, 6, 5, 3, 6, 5, 4, 2, 7, 9, 0, 8, 0,\n",
       "        7, 8, 4, 9, 3, 7, 8, 9, 0, 5, 9, 6, 2, 2, 0, 8, 6, 6, 3, 5, 3, 6, 2, 1,\n",
       "        7, 9, 9, 4])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels   # actual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cef75435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(labels == preds).item() / len(labels) \n",
    "#return true if both are same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0fa34d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION METRIC AND LOSS FUNCTION\n",
    "#in linear regression we need a way to evaluate how well our model. but the natural wa to find these is to finding the percentage\n",
    "#of labels correctlythat were predicted correctly, that is finding the accuracy.\n",
    "\n",
    "def accuracy(l1,l2):\n",
    "    return torch.sum(l1 == l2).item() / len(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c235f47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44881573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unlike accuracy , cross entropy is a continous and differentiable function that also provides good feesback for incremental \n",
    "#imporvements in a model.(a slightly higher probability for the correct label lead to the lower loss.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7c901c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9b5183f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2949, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#loss for the current batch\n",
    "loss = loss_fn(outputs, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c479b9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIMIZER\n",
    "#we are going to use optim.SGD to update the weights and biases during training, but with the higher learning rate of 1e-3\n",
    "\n",
    "learning_rate = 0.001  # hyperparameter , helps to train model as soon as .\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "63d829ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING THE MODEL\n",
    "def loss_batch(model, loss_func , xb , yb , opt=None , metric = None):\n",
    "    #calculate loss\n",
    "    preds = model(xb)\n",
    "    loss = loss_func(preds , yb)\n",
    "    \n",
    "    if opt is not None:\n",
    "        #compute gradients\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        opt.step()\n",
    "        #reset gradients\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    metric_result = None\n",
    "    if metric is not None:\n",
    "        #compute the metric\n",
    "        metric_result = metric(preds , yb)\n",
    "    \n",
    "    return loss.item(), len(xb) , metric_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3fb00e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loss_fn, valid_d1, metric=None):\n",
    "    with torch.no_grad():\n",
    "        #pass each batch through the model\n",
    "        results = [loss_batch(model, loss_fn, xb, yb, metric=metric)\n",
    "                   for xb, yb in valid_d1]\n",
    "        #separate losses, count and metrics\n",
    "        losses, nums, metrics = zip(*results)  # we separate the batch into three lists by zip\n",
    "        \n",
    "        #total size of the datasize\n",
    "        total = np.sum(nums)\n",
    "        #avg.loss across batches\n",
    "        avg_loss = np.sum(np.multiply(losses, nums)) / total\n",
    "        avg_metric = None\n",
    "        if metric is not None:\n",
    "            #avg \\. of metric across batches\n",
    "            avg_metric = np.sum(np.multiply(metrics, nums)) / total\n",
    "    return avg_loss, total, avg_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "20aaf921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.sum(preds==labels).item() / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "38442ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2878, Accuracy: 0.099625\n"
     ]
    }
   ],
   "source": [
    "val_loss, total, val_acc = evaluate(model, loss_fn, val_loader, metric=accuracy)\n",
    "print('loss: {:.4f}, Accuracy: {:4f}' .format(val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4d154314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_fn, opt, train_dl, valid_dl, metric=None):\n",
    "    for epoch in range(epochs):\n",
    "        #training\n",
    "        for xb, yb in train_dl:\n",
    "            losss,_,_=loss_batch(model, loss_fn, xb, yb, opt)\n",
    "            \n",
    "            #evaluation\n",
    "            result = evaluate(model, loss_fn, valid_dl, metric)\n",
    "            val_loss, total, val_metric = result\n",
    "            \n",
    "            #print progress\n",
    "            if metric is None:\n",
    "                print('eoch [{}/{}], Loss: {:.4f}'\n",
    "                      .format(epoch+1, epochs, val_loss))\n",
    "            else:\n",
    "                print('epoch [{}/{}], Loss: {:.4f}, {}: {:.4f}'\n",
    "                     .format(epoch+1, epochs, val_loss, metric.__name__,val_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "696fd37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#redefine the model and optimizer\n",
    "model = MnistModel()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3888ad4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/5], Loss: 2.3760, accuracy: 0.0318\n",
      "epoch [1/5], Loss: 2.3749, accuracy: 0.0323\n",
      "epoch [1/5], Loss: 2.3739, accuracy: 0.0328\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7656/465464206.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#here the  loss getting decreased and the accuray keeps increasing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7656/3186957580.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(epochs, model, loss_fn, opt, train_dl, valid_dl, metric)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;31m#evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7656/3352672133.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(model, loss_fn, valid_d1, metric)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;31m#pass each batch through the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         results = [loss_batch(model, loss_fn, xb, yb, metric=metric)\n\u001b[0m\u001b[0;32m      5\u001b[0m                    for xb, yb in valid_d1]\n\u001b[0;32m      6\u001b[0m         \u001b[1;31m#separate losses, count and metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7656/3352672133.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;31m#pass each batch through the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         results = [loss_batch(model, loss_fn, xb, yb, metric=metric)\n\u001b[0m\u001b[0;32m      5\u001b[0m                    for xb, yb in valid_d1]\n\u001b[0;32m      6\u001b[0m         \u001b[1;31m#separate losses, count and metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit(5, model, F.cross_entropy, optimizer, train_loader, val_loader, accuracy)\n",
    "#here the  loss getting decreased and the accuray keeps increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b7df6027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#replace these values with your result\n",
    "accuracies = [0.0691, 0.0696, 0.0710, 0.0723, 0.0747,\n",
    "              0.0751, 0.0764, 0.0777, 0.0784, 0.0797,\n",
    "              0.0812, 0.0825, 0.0839, 0.0852, 0.0877,\n",
    "              0.0891, 0.0901, 0.0920, 0.0928]\n",
    "plt.plot(accuracies, '-x')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('accuracy vs. No. of epoch');\n",
    "#here the accuracy increases linearly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f059cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING WITH INDIVIDUAL IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b17af313",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define tese dataset\n",
    "test_dataset = MNIST(root='data/', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3c1235ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([1, 28, 28])\n",
      "label: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[0]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('shape:', img.shape)\n",
    "print('label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "950c1b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.unsqueeze(0).shape  # it converts the image into batch of only one image, it just adds another dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "48d32f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    xb = img.unsqueeze(0)\n",
    "    yb = model(xb)\n",
    "    _, preds = torch.max(yb, dim=1)\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "433a8a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 7 ,predicted: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[0]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('label:', label, ',predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "43f20259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 0 ,predicted: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[10]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('label:', label, ',predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "77355346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 9 ,predicted: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[193]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('label:', label, ',predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7c0bf8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 4 ,predicted: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[300]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('label:', label, ',predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f80b6dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 2 ,predicted: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[1839]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('label:', label, ',predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6cd585f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.3734, accuracy: 0.0317\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=200)\n",
    "\n",
    "test_loss, total, test_acc = evaluate(model, loss_fn, test_loader, metric=accuracy)\n",
    "print('loss: {:.4f}, accuracy: {:.4f}'.format(test_loss, test_acc))\n",
    "#it is good test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "46d379aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING AND LOADING THE MODEL\n",
    "torch.save(model.state_dict(), 'mnist-logistic.pth')\n",
    "#model.state_dict() contains a weight and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "07d2ad7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[ 0.0235, -0.0187, -0.0278,  ..., -0.0247,  0.0305, -0.0130],\n",
       "                      [ 0.0056,  0.0143,  0.0002,  ..., -0.0080, -0.0058,  0.0253],\n",
       "                      [-0.0187,  0.0140,  0.0095,  ..., -0.0077, -0.0297, -0.0334],\n",
       "                      ...,\n",
       "                      [ 0.0158, -0.0159, -0.0277,  ..., -0.0296, -0.0263, -0.0207],\n",
       "                      [ 0.0089, -0.0098,  0.0142,  ...,  0.0027,  0.0207, -0.0332],\n",
       "                      [-0.0260, -0.0343,  0.0185,  ..., -0.0101,  0.0119,  0.0290]])),\n",
       "             ('linear.bias',\n",
       "              tensor([ 0.0258,  0.0343, -0.0062, -0.0147,  0.0148,  0.0144, -0.0240,  0.0320,\n",
       "                      -0.0049, -0.0108]))])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "61a50b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[ 0.0235, -0.0187, -0.0278,  ..., -0.0247,  0.0305, -0.0130],\n",
       "                      [ 0.0056,  0.0143,  0.0002,  ..., -0.0080, -0.0058,  0.0253],\n",
       "                      [-0.0187,  0.0140,  0.0095,  ..., -0.0077, -0.0297, -0.0334],\n",
       "                      ...,\n",
       "                      [ 0.0158, -0.0159, -0.0277,  ..., -0.0296, -0.0263, -0.0207],\n",
       "                      [ 0.0089, -0.0098,  0.0142,  ...,  0.0027,  0.0207, -0.0332],\n",
       "                      [-0.0260, -0.0343,  0.0185,  ..., -0.0101,  0.0119,  0.0290]])),\n",
       "             ('linear.bias',\n",
       "              tensor([ 0.0258,  0.0343, -0.0062, -0.0147,  0.0148,  0.0144, -0.0240,  0.0320,\n",
       "                      -0.0049, -0.0108]))])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we copy the weights and biases from model1 to model2\n",
    "model2 = MnistModel()\n",
    "model2.load_state_dict(torch.load('mnist-logistic.pth'))\n",
    "model2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1a1ff85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.3734, accuracy: 0.0317\n"
     ]
    }
   ],
   "source": [
    "test_loss, total, test_acc = evaluate(model2, loss_fn, test_loader, metric=accuracy)\n",
    "print('loss: {:.4f}, accuracy: {:.4f}'.format(test_loss, test_acc))\n",
    "\n",
    "#here we get the same accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b75db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summary and Further Reading\n",
    "\n",
    "#We've created a fairly sophisticated training and evaluation pipeline in this tutorial. Here's a list of the topics we've covered:\n",
    "\n",
    "# Working with images in PyTorch (using the MNIST dataset)\n",
    "# Splitting a dataset into training, validation and test sets\n",
    "# Creating PyTorch models with custom logic by extending the `nn.Module` class\n",
    "# Interpreting model ouputs as probabilities using softmax, and picking predicted labels\n",
    "# Picking a good evaluation metric (accuracy) and loss function (cross entropy) for classification problems\n",
    "# Setting up a training loop that also evaluates the model using the validation set\n",
    "# Testing the model manually on randomly picked examples \n",
    "# Saving and loading model checkpoints to avoid retraining from scratch\n",
    "\n",
    "#There's a lot of scope to experiment here, and I encourage you to use the interactive nature of Jupyter to play around with the various parameters. Here are a few ideas:\n",
    "\n",
    "# Try making the validation set smaller or larger, and see how it affects the model.\n",
    "# Try changing the learning rate and see if you can achieve the same accuracy in fewer epochs.\n",
    "# Try changing the batch size. What happens if you use too high a batch size, or too low?\n",
    "# Modify the `fit` function to also track the overall loss and accuracy on the training set, and see how it compares with the validation loss/accuracy. Can you explain why it's lower/higher?\n",
    "# Train with a small subset of the data, and see if you can reach a similar level of accuracy.\n",
    "# Try building a model for a different dataset, such as the [CIFAR10 or CIFAR100 datasets](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f93d498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a418da72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29d87ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a0fd27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
